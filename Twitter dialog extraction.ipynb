{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "from langdetect import DetectorFactory, detect\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twcs = pd.read_csv('../Chatbot/dataset/twcs/twcs.csv', nrows=20000).set_index('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_chat = df_twcs[df_twcs.inbound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in_outs = pd.merge(inbound_chat, df_twcs, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Dataset:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.last_id = 0\n",
    "        self.conv = []\n",
    "        self.company_name = ''\n",
    "        self.df_convs = pd.DataFrame(columns=['author_id', 'company_name', 'dialog'])\n",
    "        \n",
    "    def add_to_df(self, last_id, author_id, company_name, text_x, text_y):\n",
    "        if (last_id == author_id):\n",
    "            self.conv.append('participant1|'+ \" \".join(filter(lambda x:x[0]!='@', text_x.split())))\n",
    "            self.conv.append('participant2|'+ \" \".join(filter(lambda x:x[0]!='@', text_y.split())))\n",
    "        elif self.last_id != 0:\n",
    "            if len(self.conv) > 0:\n",
    "                id = len(self.df_convs)\n",
    "                self.df_convs.loc[id, 'author_id'] = self.last_id\n",
    "                self.df_convs.loc[id, 'company_name'] = self.company_name\n",
    "                self.df_convs.loc[id, 'dialog'] = self.conv\n",
    "                self.conv = []\n",
    "            self.last_id = author_id\n",
    "            \n",
    "        else:\n",
    "            self.conv.append('participant1|'+ text_x)\n",
    "            self.conv.append('participant2|'+ text_y)\n",
    "            self.last_id = author_id\n",
    "            self.company_name = company_name\n",
    "    def create_df(self):\n",
    "        [self.add_to_df(self.last_id, row[0], row[1], row[2], row[3]) for row in self.df[['author_id_x', 'author_id_y','text_x', 'text_y']].values]\n",
    "        return self.df_convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    clean_text = []\n",
    "    text = re.sub(\"''\", \"\", text)\n",
    "    text = \" \".join(filter(lambda x:x[0]!='@', text.split())) # Remove the words starts with '@'\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \", text)\n",
    "    clean_text = [wn.lemmatize(word, pos=\"v\") for word in word_tokenize(text.lower()) \n",
    "                  if (word not in stop_words and word not in list(string.punctuation))]\n",
    "    return clean_text\n",
    "    #return \" \".join([word for word in clean_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_participants(conversation):\n",
    "    part1_dialog = []\n",
    "    part2_dialog = []\n",
    "    conv_token = []\n",
    "    for conv in conversation:\n",
    "        dialog = conv.split('|')\n",
    "        if dialog[0] == 'participant1':\n",
    "            part1_dialog.append(dialog[1])\n",
    "        else:\n",
    "            part2_dialog.append(dialog[1])\n",
    "            \n",
    "    if (len(part1_dialog) > 0):\n",
    "        part1_str = \" \".join([word for word in part1_dialog])\n",
    "        conv_token.append(clean_text(part1_str))\n",
    "    if (len(part2_dialog) > 0):\n",
    "        part2_str = \" \".join([word for word in part2_dialog])\n",
    "        conv_token.append(clean_text(part2_str))\n",
    "    return conv_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_prep = Preprocess_Dataset(df_in_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tw_convs = cls_prep.create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['participant1|I did this some time ago now but haven’t heard from you...',\n",
       " 'participant2|Hi Richard, I apologize for the delayed response time. Please DM your conf # so I can review your trip details. *TLT... 1/2',\n",
       " \"participant1|Actually, I just looked again and they disagree and say it's on you. Any idea what I should do? https://t.co/twIogKd3Kx\",\n",
       " 'participant2|Hello, Richard! Please DM your confirmation# and I will try to assist. *TCC',\n",
       " 'participant1|Hi - and thanks. Think I just figured this out. Would it be you’re not running the MEX-MID flight so I need to check in via AeroMexico?',\n",
       " \"participant2|Actually, I just looked again and they disagree and say it's on you. Any idea what I should do? https://t.co/twIogKd3Kx\",\n",
       " \"participant1|I'm flying JFK-MEX-MID tomorrow and you say I'm booked in, but it looks like it's just the first leg. Can you check, please?\",\n",
       " 'participant2|Hi, Richard. Can you pls DM your confirmation number so I may look into this matter for you? Thanks! *TJF https://t.co/6iDGBJAc2m']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_tw_convs['dialog'][52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw_convs['conv_tokens'] = df_tw_convs['dialog'].apply(lambda x: split_participants(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lang(conv):\n",
    "    lng = 'en'\n",
    "    if(len(conv)>1):\n",
    "        text = \" \".join([word for word in (conv[0] + conv[1])])\n",
    "        lng = detect(text)\n",
    "    return lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw_convs['lang'] = df_tw_convs['conv_tokens'].apply(lambda x: check_lang(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    2012\n",
       "ja      27\n",
       "es      19\n",
       "fr      13\n",
       "nl       9\n",
       "de       6\n",
       "it       5\n",
       "af       5\n",
       "pt       4\n",
       "da       3\n",
       "no       3\n",
       "ro       2\n",
       "et       2\n",
       "cy       1\n",
       "fi       1\n",
       "ca       1\n",
       "sv       1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the language used for tweet\n",
    "df_tw_convs['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for English\n",
    "df_tw_convs = df_tw_convs[(df_tw_convs['lang'] == 'en')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ready',\n",
       "  'next',\n",
       "  'iphone',\n",
       "  'join',\n",
       "  'iphone',\n",
       "  'upgrade',\n",
       "  'program',\n",
       "  'free',\n",
       "  'https',\n",
       "  'co',\n",
       "  'elb',\n",
       "  'yqspf',\n",
       "  'ready',\n",
       "  'next',\n",
       "  'iphone',\n",
       "  'join',\n",
       "  'iphone',\n",
       "  'upgrade',\n",
       "  'program',\n",
       "  'free',\n",
       "  'https',\n",
       "  'co',\n",
       "  'elb',\n",
       "  'yqspf',\n",
       "  'ready',\n",
       "  'next',\n",
       "  'iphone',\n",
       "  'join',\n",
       "  'iphone',\n",
       "  'upgrade',\n",
       "  'program',\n",
       "  'free',\n",
       "  'https',\n",
       "  'co',\n",
       "  'elb',\n",
       "  'yqspf'],\n",
       " ['please',\n",
       "  'let',\n",
       "  'people',\n",
       "  'pay',\n",
       "  'higher',\n",
       "  'monthly',\n",
       "  'cost',\n",
       "  'eliminate',\n",
       "  'ridiculously',\n",
       "  'high',\n",
       "  'cost',\n",
       "  'cost',\n",
       "  'per',\n",
       "  'year',\n",
       "  'anyone',\n",
       "  'else',\n",
       "  'number',\n",
       "  'unlimited',\n",
       "  'service',\n",
       "  'installment',\n",
       "  'iphone',\n",
       "  'x',\n",
       "  'jump',\n",
       "  'program',\n",
       "  'go',\n",
       "  'get',\n",
       "  'iphone',\n",
       "  'x']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted = split_participants(df_tw_convs['dialog'][65])\n",
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
